{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pless_nfs/home/zeyu/github/gwuvision/reverse-pheno\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 31 18:37:49 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:02:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    25W / 250W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:82:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    31W / 250W |  13585MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     21455      C   ...3/envs/pytorch/bin/python    13583MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from genetic_marker_dataset import GeneImageDataset\n",
    "from torchvision import transforms\n",
    "from experimental.network.embedding import SoftmaxEmbeddingNet\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([transforms.CenterCrop(1024),\n",
    "                                      transforms.Resize(512),\n",
    "                                      transforms.ToTensor()])\n",
    "ds = GeneImageDataset(folder='/data/shared/genetic_marker_datasets/', \n",
    "                     sensor='rgb', \n",
    "                     transform=image_transform)\n",
    "dl = DataLoader(ds, batch_size=30, shuffle=False, num_workers=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxEmbeddingNet(375)\n",
    "state_dict = torch.load('results/model/s9_pretrained_rgb.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict['model_state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on GPU\n"
     ]
    }
   ],
   "source": [
    "ebd_model = model.backbone\n",
    "ebd_model.cuda()\n",
    "print('Model loaded on GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebd_1024_list = []\n",
    "ebd_128_list = []\n",
    "\n",
    "def gap_layer_hook(module, input, output):\n",
    "    ebd_1024_list.append(output.squeeze(-1).unsqueeze(-1).cpu().detach())\n",
    "    \n",
    "gap_layer_hook_handle = ebd_model.avgpool.register_forward_hook(gap_layer_hook)\n",
    "\n",
    "ebd_model.eval()\n",
    "with torch.no_grad():\n",
    "    for img, label in tqdm(dl):\n",
    "        ebd = ebd_model(img.cuda())\n",
    "        ebd_128_list.append(ebd.cpu().detach())\n",
    "    ebd_128 = torch.cat(ebd_128_list, dim=0)\n",
    "    ebd_1024 = torch.cat(ebd_1024_list, dim=0)\n",
    "\n",
    "gap_layer_hook_handle.remove()\n",
    "save_path = 'results/snp_pred/s9_jpg_rgb_gene_ds_img_ebd.pth'\n",
    "if not os.path.exists(os.path.dirname(save_path)):\n",
    "    os.makedirs(os.path.dirname(save_path))\n",
    "torch.save({'ebd_128': ebd_128, 'ebd_2048': ebd_1024},\n",
    "            save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([transforms.CenterCrop(512),\n",
    "                                      transforms.ToTensor()])\n",
    "ds = GeneImageDataset(folder='/data/shared/genetic_marker_datasets/',\n",
    "                      sensor='3d', \n",
    "                      transform=image_transform)\n",
    "dl = DataLoader(ds, batch_size=30, shuffle=False, num_workers=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxEmbeddingNet(375)\n",
    "state_dict = torch.load('results/model/s9_pretrained_3d.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict['model_state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on GPU\n"
     ]
    }
   ],
   "source": [
    "ebd_model = model.backbone\n",
    "ebd_model.cuda()\n",
    "print('Model loaded on GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cf07d00d4040f1ba2a99e32796a859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebd_1024_list = []\n",
    "ebd_128_list = []\n",
    "\n",
    "def gap_layer_hook(module, input, output):\n",
    "    ebd_1024_list.append(output.squeeze().cpu().detach())\n",
    "    \n",
    "gap_layer_hook_handle = ebd_model.avgpool.register_forward_hook(gap_layer_hook)\n",
    "\n",
    "ebd_model.eval()\n",
    "with torch.no_grad():\n",
    "    for img, label in tqdm(dl):\n",
    "        ebd = ebd_model(img.cuda())\n",
    "        ebd_128_list.append(ebd.cpu().detach())\n",
    "    ebd_128 = torch.cat(ebd_128_list, dim=0)\n",
    "    ebd_1024 = torch.cat(ebd_1024_list, dim=0)\n",
    "\n",
    "gap_layer_hook_handle.remove()\n",
    "save_path = 'results/snp_pred/s9_jpg_3d_gene_ds_img_ebd.pth'\n",
    "if not os.path.exists(os.path.dirname(save_path)):\n",
    "    os.makedirs(os.path.dirname(save_path))\n",
    "torch.save({'ebd_128': ebd_128, 'ebd_1024': ebd_1024},\n",
    "            save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "13bd2d5660c64985bc648516dacfd8fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1b8d05cc60484e0ca6e10ab79e47ca9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "20a5d1a628bc482484c3f588fe6bd19c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dd51aae4eea5436c8457819216813efe",
       "style": "IPY_MODEL_2a573efe1daa4eff81e198aa67aad16c",
       "value": "100%"
      }
     },
     "246aeb7f178f42fb9e9a7af60d90814e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2a573efe1daa4eff81e198aa67aad16c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3bdba2934fd646ef8aa051a506d8f7e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "43db4b0f5b7841a9a891c2d393959977": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_566c4d16b35e456c99e5e43d2b28ac24",
       "max": 17872,
       "style": "IPY_MODEL_6909136dc061422cb87ea84f83ac65d0",
       "value": 17872
      }
     },
     "450d8b4dacd24354a2cd2fa7f820a9fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_13bd2d5660c64985bc648516dacfd8fd",
       "style": "IPY_MODEL_1b8d05cc60484e0ca6e10ab79e47ca9a",
       "value": "100%"
      }
     },
     "46cecc61ec2f47b595abd93ffc5fe10e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_20a5d1a628bc482484c3f588fe6bd19c",
        "IPY_MODEL_43db4b0f5b7841a9a891c2d393959977",
        "IPY_MODEL_5eefce5d1f00492d9ea327ebef4c5af8"
       ],
       "layout": "IPY_MODEL_b76a53b4d5b346ba9d49f2def3de7842"
      }
     },
     "4721c34cf7f54577af7e430fc6eefbf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "566c4d16b35e456c99e5e43d2b28ac24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5eefce5d1f00492d9ea327ebef4c5af8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3bdba2934fd646ef8aa051a506d8f7e7",
       "style": "IPY_MODEL_4721c34cf7f54577af7e430fc6eefbf5",
       "value": " 17872/17872 [1:27:07&lt;00:00,  3.42it/s]"
      }
     },
     "640d260e97d2496a8a88f5dd4f9d0d32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6909136dc061422cb87ea84f83ac65d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "70747000f845481ca2664758c92f32fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9a21f1e6e23a474c946ab33f029dfcb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_640d260e97d2496a8a88f5dd4f9d0d32",
       "max": 18120,
       "style": "IPY_MODEL_246aeb7f178f42fb9e9a7af60d90814e",
       "value": 18120
      }
     },
     "b76a53b4d5b346ba9d49f2def3de7842": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8ce6d6a54a84babbd6510bd9b1a83af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "caebc31a9b264a3db025c85f22e00d92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dd51aae4eea5436c8457819216813efe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1cf07d00d4040f1ba2a99e32796a859": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_450d8b4dacd24354a2cd2fa7f820a9fb",
        "IPY_MODEL_9a21f1e6e23a474c946ab33f029dfcb8",
        "IPY_MODEL_e6261b9094c64403bf7da45e846ded5f"
       ],
       "layout": "IPY_MODEL_70747000f845481ca2664758c92f32fa"
      }
     },
     "e6261b9094c64403bf7da45e846ded5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_caebc31a9b264a3db025c85f22e00d92",
       "style": "IPY_MODEL_c8ce6d6a54a84babbd6510bd9b1a83af",
       "value": " 18120/18120 [1:28:52&lt;00:00,  3.40it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
